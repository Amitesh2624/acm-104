\documentclass{article}
\usepackage{graphicx}% Required for inserting images
\usepackage{lindrew}
\usepackage{pdfpages}
\usepackage[shortlabels]{enumitem}
\usepackage{matlab-prettifier}
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{ACM 104 Problem Set 4}
\author{Amitesh Pandey}
\date{November 2024}
\begin{document}
\maketitle
\section*{Problem 1: Least Squares Solution}
\emph{Solution. }The least squares solution to $Ax = b$ is unique if and only if the columns of $A$ are linearly independent. It's easy to see that the columns of $A$ indeed are linearly independent. For invertible $A^{T}A$, the solution is given by
\begin{equation*}
    \Hat{x} = (A^{T}A)^{-1}A^{T}b
\end{equation*}
This means that 
\begin{align*}
    \Hat{x} &= \left(\begin{pmatrix}
        1 & 0 & 1 & -3\\
        2 & -2 & 5 & 1\\
        -1 & 3 & -1& 1
    \end{pmatrix} \cdot \begin{pmatrix}
        1 & 2 & -1\\
        0 & -2 & 3\\
        1 & 5 & -1\\
        -3 & 1 & 1
    \end{pmatrix}\right)^{-1}\begin{pmatrix}
        1 & 0 & 1 & -3\\
        2 & -2 & 5 & 1\\
        -1 & 3 & -1& 1
    \end{pmatrix}\begin{pmatrix}
        0\\
        5\\
        6\\
        8
    \end{pmatrix}\\
    &= \begin{pmatrix}
        11 & 4 & -5\\
        4 & 34 & -12\\
        -5 & -12 & 12
    \end{pmatrix}^{-1}\begin{pmatrix}
        1 & 0 & 1 & -3\\
        2 & -2 & 5 & 1\\
        -1 & 3 & -1& 1
    \end{pmatrix}\cdot\begin{pmatrix}
        0\\
        5\\
        6\\
        8
    \end{pmatrix} \\
    &= \begin{pmatrix}
        \frac{132}{1171} & \frac{6}{1171} & \frac{61}{1171}\\
        \frac{6}{1171} & \frac{107}{2342} & \frac{56}{1171}\\
        \frac{61}{1171} & \frac{56}{1171}& \frac{179}{1171}
    \end{pmatrix}\cdot \begin{pmatrix}
        -18\\
        28\\
        7
    \end{pmatrix} = \begin{pmatrix}
        -1\\
        2\\
        3
    \end{pmatrix}
\end{align*}
The least squares error is given by $\varepsilon = ||A\hat{x}- b||^2$, but $A\hat{x}$ exactly equals $b$ for us, so the least squares error is 0. 
\section*{Problem 2: Interpolation for Integration}
\emph{Solution. }(a) Given only two interpolating points $x_{0}, x_{1}$, we will have an interpolating polynomial of degree 1, or $p_{1}(x)$. Generally, this polynomial for $f(x)$ is given by
\begin{equation*}
    p_{1}(x) = f(x_0)\frac{x - x_1}{x_0 - x_1} + f(x_1)\frac{x - x_0}{x_1 - x_0} = \frac{f(x_0) - f(x_1)}{x_0 - x_1}x + \frac{x_0 f(x_1) - x_1 f(x_0)}{x_0 - x_1}
\end{equation*}
Letting $x_0 = a, x_1 = b$, we obtain
\begin{equation*}
    p_1(x) = \frac{f(b) - f(a)}{b - a}x + \frac{a f(b) - bf(a)}{b-a}
\end{equation*}
Then
\begin{equation*}
    \int_{a}^{b}f(x)\text{d}x \approx \int_{a}^{b}\left(\frac{f(b) - f(a)}{b - a}x + \frac{a f(b) - bf(a)}{b-a}\right)\text{d}x = \left(\frac{b-a}{2}\right)\left(f(b) + f(a)\right)
\end{equation*}
\noindent{(b)} Now, letting $x_0 = \frac{2}{3}a + \frac{1}{3}b$, $x_1 = \frac{1}{3}a + \frac{2}{3}b$, we have
\begin{equation*}
    p_{1}(x) = \frac{f(x_{0}) - f(x_{1})}{b-a}(3x) + 3\left(\frac{x_0 f(x_1) - x_1 f(x_0)}{b-a}\right)
\end{equation*}
\begin{equation*}
    \int_{a}^{b} f(x)\text{d}x \approx \int_{a}^{b}\left(\frac{f(x_{0}) - f(x_{1})}{b-a}(3x) + 3\left(\frac{x_0 f(x_1) - x_1 f(x_0)}{b-a}\right)\right)\text{d}x
\end{equation*}
This gets us
\begin{equation*}
    \frac{3bf(x_0)}{2} + \frac{3af(x_0)}{2} - \frac{3bf(x_1)}{2} - \frac{3af(x_1)}{2} + 3x_0 f(x_1)  - 3x_{1}f(x_{0}) = \frac{b-a}{2}\left(f(x_0) + f(x_1)\right)
\end{equation*}
Finally, we have
\begin{equation*}
    \int_{a}^{b}f(x)\text{d}x \approx \left( \frac{b-a}{2}\right)\left(f\left(\frac{2}{3}a + \frac{1}{3}b\right) + f\left(\frac{1}{3}a + \frac{2}{3}b\right)\right)
\end{equation*}
(c) For $e^{x}$ from $0$ to $1$
\begin{enumerate}
    \item Trapezoid Rule: 
    \begin{equation*}
        \int_{0}^{1}e^{x}\text{d}x \approx \frac{1}{2}(e +1) = 1.855
    \end{equation*}
    \item Open Rule: 
    \begin{equation*}
        \int_{0}^{1}e^{x}\text{d}x \approx \frac{1}{2}(e^{1/3} + e^{2/3}) = 1.671
    \end{equation*}
\end{enumerate}
Actual value: $e - 1 = 1.71$, so the open rule is closer. Now for $\sin(x)$ from $0$ to $\pi$, we have
\begin{enumerate}
    \item Trapezoid Rule:
    \begin{equation*}
    \int_{0}^{\pi}\sin(x)\text{d}x \approx \frac{\pi}{2}(0) = 0
\end{equation*}
    \item Open Rule
    \begin{equation*}
        \int_{0}^{\pi}\sin(x)\text{d}x \approx \frac{\pi}{2}\left(\sin\left(\frac{\pi}{3}\right) + \sin\left(\frac{2\pi}{3}\right)\right) = 0.866
    \end{equation*}
\end{enumerate}
Actual value: $2$, so open rule is closer.
\section*{Problem 3: Least Squares to Data Fitting}
\emph{Solution. }(a) We will have $r$ such that \begin{equation*}
\begin{aligned}
r_i & =y^{(i)}-f\left(x_1^{(i)}, x_2^{(i)}\right) \\
& =y^{(i)}-\left[\begin{array}{llll}
1 & x_1^{(i)} & x_2^{(i)} & x_1^{(i)} x_2^{(i)}
\end{array}\right]\left[\begin{array}{c}
\beta_0^* \\
\beta_1^* \\
\beta_2^* \\
\beta_3^*
\end{array}\right]
\end{aligned}
\end{equation*}
Overall $r$ is as such
\begin{equation*}
r=\left[\begin{array}{c}
y^{(1)} \\
y^{(2)} \\
\vdots \\
\vdots \\
y^{(m)}
\end{array}\right]-\left[\begin{array}{cccc}
1 & x_1^{(1)} & x_2^{(1)} & x_1^{(1)} x_2^{(1)} \\
1 & x_1^{(2)} & x_2^{(2)} & x_1^{(2)} x_2^{(2)} \\
\vdots & \vdots & \vdots & \vdots \\
\vdots & \vdots & \vdots & \vdots \\
1 & x_1^{(m)} & x_2^{(m)} & x_1^{(m)} x_2^{(m)}
\end{array}\right]\left[\begin{array}{c} 
\beta_0^* \\
\beta_1^* \\
\beta_2^* \\
\beta_3^*
\end{array}\right]
\end{equation*}


\end{document}
